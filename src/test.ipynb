{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nhits import NHiTS\n",
    "import yaml\n",
    "\n",
    "# Import needed libraries\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.dataset import UnivariateTSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2569,  0.2569,  0.2569,  ..., -1.0972, -1.0972, -1.0972],\n",
       "        [ 0.8754,  0.8754,  0.8754,  ..., -1.5343, -1.5343, -1.5343],\n",
       "        [ 0.0558,  0.0558,  0.0558,  ..., -1.8765, -1.8765, -1.8765],\n",
       "        ...,\n",
       "        [-2.4085, -2.4085, -2.4085,  ..., -0.7587, -0.7587, -0.7587],\n",
       "        [-0.7075, -0.7075, -0.7075,  ..., -0.6427, -0.6427, -0.6427],\n",
       "        [ 0.9549,  0.9549,  0.9549,  ...,  0.1177,  0.1177,  0.1177]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((128,1,30))\n",
    "F.interpolate(x, size=120, mode='nearest').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholashoffs/code/nhits/venv/lib/python3.11/site-packages/torch/nn/functional.py:3954: UserWarning: The operator 'aten::upsample_linear1d.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  return torch._C._nn.upsample_linear1d(input, output_size, align_corners, scale_factors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 89.31254577636719\n",
      "Epoch 0: 20.955902099609375\n",
      "Epoch 0: 13.797274589538574\n",
      "Epoch 0: 12.574091911315918\n",
      "Epoch 0: 12.430716514587402\n",
      "Epoch 0: 9.117605209350586\n",
      "Epoch 0: 8.271800994873047\n",
      "Epoch 0: 5.746265411376953\n",
      "Epoch 0: 5.337698936462402\n",
      "Epoch 0: 3.9979896545410156\n",
      "Epoch 0: 4.728146076202393\n",
      "Epoch 0: 3.7525758743286133\n",
      "Epoch 0: 4.205483913421631\n",
      "Epoch 0: 4.181402206420898\n",
      "Epoch 0: 3.1608664989471436\n",
      "Epoch 0: 2.9673118591308594\n",
      "Epoch 0: 5.467883110046387\n",
      "Epoch 0: 3.0655744075775146\n",
      "Epoch 0: 3.2241456508636475\n",
      "Epoch 0: 2.822096586227417\n",
      "Epoch 0: 3.7045955657958984\n",
      "Epoch 0: 3.6705825328826904\n",
      "Epoch 0: 3.453881025314331\n",
      "Epoch 0: 2.3318605422973633\n",
      "Epoch 0: 2.723663091659546\n",
      "Epoch 0: 2.9758071899414062\n",
      "Epoch 0: 3.0655832290649414\n",
      "Epoch 0: 5.182059288024902\n",
      "Epoch 0: 2.4338178634643555\n",
      "Epoch 0: 2.755636215209961\n",
      "Epoch 0: 2.2464184761047363\n",
      "Epoch 0: 2.97724986076355\n",
      "Epoch 0: 4.221317291259766\n",
      "Epoch 0: 3.1607441902160645\n",
      "Epoch 0: 2.621744394302368\n",
      "Epoch 0: 3.5633323192596436\n",
      "Epoch 0: 2.6294546127319336\n",
      "Epoch 0: 3.049595355987549\n",
      "Epoch 0: 2.1867055892944336\n",
      "Epoch 0: 2.838696241378784\n",
      "Epoch 0: 2.32300066947937\n",
      "Epoch 0: 3.038593292236328\n",
      "Epoch 0: 2.2020723819732666\n",
      "Epoch 0: 2.013582229614258\n",
      "Epoch 0: 4.171600341796875\n",
      "Epoch 0: 2.3497772216796875\n",
      "Epoch 0: 2.444756507873535\n",
      "Epoch 0: 2.9348368644714355\n",
      "Epoch 0: 2.4720826148986816\n",
      "Epoch 0: 2.361095905303955\n",
      "Epoch 0: 3.037933349609375\n",
      "Epoch 0: 2.3504133224487305\n",
      "Epoch 0: 2.317159652709961\n",
      "Epoch 0: 3.6336112022399902\n",
      "Epoch 0: 2.26330828666687\n",
      "Epoch 0: 2.4771833419799805\n",
      "Epoch 0: 2.6360318660736084\n",
      "Epoch 0: 2.2406702041625977\n",
      "Epoch 0: 2.1627492904663086\n",
      "Epoch 0: 2.412304162979126\n",
      "Epoch 0: 2.4366157054901123\n",
      "Epoch 0: 2.9681053161621094\n",
      "Epoch 0: 2.434654474258423\n",
      "Epoch 0: 2.2386364936828613\n",
      "Epoch 0: 2.3992080688476562\n",
      "Epoch 0: 2.4701123237609863\n",
      "Epoch 0: 2.11688232421875\n",
      "Epoch 0: 2.5424065589904785\n",
      "Epoch 0: 2.440580368041992\n",
      "Epoch 0: 1.9939346313476562\n",
      "Epoch 0: 2.2482593059539795\n",
      "Epoch 0: 2.1582014560699463\n",
      "Epoch 0: 2.4961328506469727\n",
      "Epoch 0: 2.9161930084228516\n",
      "Epoch 0: 2.458765983581543\n",
      "Epoch 0: 2.681708812713623\n",
      "Epoch 0: 2.2123336791992188\n",
      "Epoch 0: 2.615133762359619\n",
      "Epoch 0: 2.508617401123047\n",
      "Epoch 0: 2.582954168319702\n",
      "Epoch 0: 2.8896970748901367\n",
      "Epoch 0: 2.7289304733276367\n",
      "Epoch 0: 2.237804651260376\n",
      "Epoch 0: 2.342639446258545\n",
      "Epoch 0: 2.76227068901062\n",
      "Epoch 0: 2.445342540740967\n",
      "Epoch 0: 2.6933937072753906\n",
      "Epoch 0: 2.2727017402648926\n",
      "Epoch 0: 2.0158166885375977\n",
      "Epoch 0: 2.651264190673828\n",
      "Epoch 0: 2.110731601715088\n",
      "Epoch 0: 2.0834224224090576\n",
      "Epoch 0: 2.536045789718628\n",
      "Epoch 0: 2.1272032260894775\n",
      "Epoch 0: 2.5421552658081055\n",
      "Epoch 0: 2.7292277812957764\n",
      "Epoch 0: 2.4089014530181885\n",
      "Epoch 0: 2.5795085430145264\n",
      "Epoch 0: 2.1479525566101074\n",
      "Epoch 0: 2.016420364379883\n",
      "Epoch 0: 2.2705416679382324\n",
      "Epoch 0: 2.151942014694214\n",
      "Epoch 0: 3.6405415534973145\n",
      "Epoch 0: 2.120081663131714\n",
      "Epoch 0: 2.2648744583129883\n",
      "Epoch 0: 3.101780652999878\n",
      "Epoch 0: 2.1992156505584717\n",
      "Epoch 0: 3.003331184387207\n",
      "Epoch 0: 2.742326498031616\n",
      "Epoch 0: 1.995169997215271\n",
      "Epoch 0: 3.042001247406006\n",
      "Epoch 0: 3.1116690635681152\n",
      "Epoch 0: 2.2211523056030273\n",
      "Epoch 0: 2.4403486251831055\n",
      "Epoch 0: 2.1853129863739014\n",
      "Epoch 0: 2.272982597351074\n",
      "Epoch 0: 2.08743953704834\n",
      "Epoch 0: 2.4875288009643555\n",
      "Epoch 0: 2.319396495819092\n",
      "Epoch 0: 2.2587544918060303\n",
      "Epoch 0: 3.411003828048706\n",
      "Epoch 0: 2.1282546520233154\n",
      "Epoch 0: 2.048395872116089\n",
      "Epoch 0: 1.760523796081543\n",
      "Epoch 0: 2.402589797973633\n",
      "Epoch 0: 2.0038020610809326\n",
      "Epoch 0: 2.2420856952667236\n",
      "Epoch 0: 2.6241543292999268\n",
      "Epoch 0: 1.8917182683944702\n",
      "Epoch 0: 2.126213788986206\n",
      "Epoch 0: 2.4309327602386475\n",
      "Epoch 0: 2.392577648162842\n",
      "Epoch 0: 2.5375115871429443\n",
      "Epoch 0: 2.8523433208465576\n",
      "Epoch 0: 2.9466006755828857\n",
      "Epoch 0: 2.1117095947265625\n",
      "Epoch 0: 2.0803515911102295\n",
      "Epoch 0: 2.41694974899292\n",
      "Epoch 0: 2.1423964500427246\n",
      "Epoch 0: 2.258394718170166\n",
      "Epoch 0: 2.3824269771575928\n",
      "Epoch 0: 2.325249195098877\n",
      "Epoch 0: 2.263455629348755\n",
      "Epoch 0: 2.0252537727355957\n",
      "Epoch 0: 2.3878746032714844\n",
      "Epoch 0: 2.100980758666992\n",
      "Epoch 0: 2.0629119873046875\n",
      "Epoch 0: 2.4753451347351074\n",
      "Epoch 0: 2.367283344268799\n",
      "Epoch 0: 2.260744571685791\n",
      "Epoch 0: 2.360450267791748\n",
      "Epoch 0: 2.4570577144622803\n",
      "Epoch 0: 2.111842632293701\n",
      "Epoch 0: 2.1783502101898193\n",
      "Epoch 0: 2.5643157958984375\n",
      "Epoch 0: 2.224005699157715\n",
      "Epoch 0: 2.2963547706604004\n",
      "Epoch 0: 2.2638304233551025\n",
      "Epoch 0: 2.280123710632324\n",
      "Epoch 0: 2.231658697128296\n",
      "Epoch 0: 1.936476469039917\n",
      "Epoch 0: 2.488077163696289\n",
      "Epoch 0: 2.621093273162842\n",
      "Epoch 0: 2.0489022731781006\n",
      "Epoch 0: 1.9365381002426147\n",
      "Epoch 0: 2.324397563934326\n",
      "Epoch 0: 2.330169200897217\n",
      "Epoch 0: 2.4085404872894287\n",
      "Epoch 0: 1.943434476852417\n",
      "Epoch 0: 2.246798515319824\n",
      "Epoch 0: 2.1172845363616943\n",
      "Epoch 0: 2.4980998039245605\n",
      "Epoch 0: 2.245258092880249\n",
      "Epoch 0: 1.9641565084457397\n",
      "Epoch 0: 2.4508566856384277\n",
      "Epoch 0: 1.9476678371429443\n",
      "Epoch 0: 1.847955584526062\n",
      "Epoch 0: 2.4800634384155273\n",
      "Epoch 0: 1.9077587127685547\n",
      "Epoch 0: 2.0381600856781006\n",
      "Epoch 0: 1.8822578191757202\n",
      "Epoch 0: 2.0305585861206055\n",
      "Epoch 0: 2.667104482650757\n",
      "Epoch 0: 2.100958824157715\n",
      "Epoch 0: 2.1559886932373047\n",
      "Epoch 0: 1.6820539236068726\n",
      "Epoch 0: 1.8533761501312256\n",
      "Epoch 0: 1.7719218730926514\n",
      "Epoch 0: 2.1474521160125732\n",
      "Epoch 0: 1.9745445251464844\n",
      "Epoch 0: 2.1099681854248047\n",
      "Epoch 0: 1.9431613683700562\n",
      "Epoch 0: 2.169527053833008\n",
      "Epoch 0: 2.2139101028442383\n",
      "Epoch 0: 1.9681851863861084\n",
      "Epoch 0: 2.13295841217041\n",
      "Epoch 0: 2.6799240112304688\n",
      "Epoch 0: 2.13818097114563\n",
      "Epoch 0: 2.051713466644287\n",
      "Epoch 0: 1.9462862014770508\n",
      "Epoch 0: 2.486745834350586\n",
      "Epoch 0: 2.0037472248077393\n",
      "Epoch 0: 2.115971803665161\n",
      "Epoch 0: 2.181100368499756\n",
      "Epoch 0: 2.348459005355835\n",
      "Epoch 0: 2.2187302112579346\n",
      "Epoch 0: 2.1060569286346436\n",
      "Epoch 0: 2.570545196533203\n",
      "Epoch 0: 2.044674873352051\n",
      "Epoch 0: 1.9929637908935547\n",
      "Epoch 0: 2.3402554988861084\n",
      "Epoch 0: 2.043897867202759\n",
      "Epoch 0: 2.583409309387207\n",
      "Epoch 0: 2.361865758895874\n",
      "Epoch 0: 2.029268741607666\n",
      "Epoch 0: 1.9244914054870605\n",
      "Epoch 0: 2.8468894958496094\n",
      "Epoch 0: 2.0117928981781006\n",
      "Epoch 0: 2.074270009994507\n",
      "Epoch 0: 1.8663222789764404\n",
      "Epoch 0: 2.017110586166382\n",
      "Epoch 0: 2.294076681137085\n",
      "Epoch 0: 2.128302574157715\n",
      "Epoch 0: 2.3947057723999023\n",
      "Epoch 0: 1.764512538909912\n",
      "Epoch 0: 1.8295234441757202\n",
      "Epoch 0: 1.7872966527938843\n",
      "Epoch 0: 2.084691047668457\n",
      "Epoch 0: 2.038959503173828\n",
      "Epoch 0: 2.0689525604248047\n",
      "Epoch 0: 2.4842236042022705\n",
      "Epoch 0: 1.6819419860839844\n",
      "Epoch 0: 1.654388427734375\n",
      "Epoch 0: 1.8660426139831543\n",
      "Epoch 0: 2.170597553253174\n",
      "Epoch 0: 1.9583371877670288\n",
      "Epoch 0: 2.3593108654022217\n",
      "Epoch 0: 1.8263492584228516\n",
      "Epoch 0: 1.7558009624481201\n",
      "Epoch 0: 2.214877128601074\n",
      "Epoch 0: 1.8586101531982422\n",
      "Epoch 0: 2.1479411125183105\n",
      "Epoch 0: 2.1591551303863525\n",
      "Epoch 0: 2.389347791671753\n",
      "Epoch 0: 1.8306965827941895\n",
      "Epoch 0: 2.0831408500671387\n",
      "Epoch 0: 1.9952988624572754\n",
      "Epoch 0: 2.25602126121521\n",
      "Epoch 0: 1.9731643199920654\n",
      "Epoch 0: 2.1873650550842285\n",
      "Epoch 0: 2.1695289611816406\n",
      "Epoch 0: 1.8493337631225586\n",
      "Epoch 0: 1.7576225996017456\n",
      "Epoch 0: 1.929974913597107\n",
      "Epoch 0: 1.9539923667907715\n",
      "Epoch 0: 1.977540373802185\n",
      "Epoch 0: 3.4278132915496826\n",
      "Epoch 0: 1.9739267826080322\n",
      "Epoch 0: 1.7115750312805176\n",
      "Epoch 0: 1.8006908893585205\n",
      "Epoch 0: 2.256237506866455\n",
      "Epoch 0: 2.4032793045043945\n",
      "Epoch 0: 1.8553035259246826\n",
      "Epoch 0: 2.2375707626342773\n",
      "Epoch 0: 2.386141777038574\n",
      "Epoch 0: 1.995077133178711\n",
      "Epoch 0: 1.7497189044952393\n",
      "Epoch 0: 2.757153034210205\n",
      "Epoch 0: 2.0073401927948\n",
      "Epoch 0: 1.8762882947921753\n",
      "Epoch 0: 2.100170612335205\n",
      "Epoch 0: 2.0622262954711914\n",
      "Epoch 1: 2.3875250816345215\n",
      "Epoch 1: 1.9230540990829468\n",
      "Epoch 1: 2.531827926635742\n",
      "Epoch 1: 2.1941757202148438\n",
      "Epoch 1: 2.101500988006592\n",
      "Epoch 1: 2.7281174659729004\n",
      "Epoch 1: 2.016854763031006\n",
      "Epoch 1: 2.0952260494232178\n",
      "Epoch 1: 2.1643030643463135\n",
      "Epoch 1: 2.023968458175659\n",
      "Epoch 1: 2.294431447982788\n",
      "Epoch 1: 1.7653611898422241\n",
      "Epoch 1: 2.1520087718963623\n",
      "Epoch 1: 3.0112063884735107\n",
      "Epoch 1: 1.8862069845199585\n",
      "Epoch 1: 2.0243895053863525\n",
      "Epoch 1: 1.840804100036621\n",
      "Epoch 1: 1.9552106857299805\n",
      "Epoch 1: 1.9347801208496094\n",
      "Epoch 1: 1.9438440799713135\n",
      "Epoch 1: 2.3433480262756348\n",
      "Epoch 1: 1.9104037284851074\n",
      "Epoch 1: 1.9825246334075928\n",
      "Epoch 1: 1.89560067653656\n",
      "Epoch 1: 2.010037899017334\n",
      "Epoch 1: 1.869520902633667\n",
      "Epoch 1: 2.4521913528442383\n",
      "Epoch 1: 2.153815269470215\n",
      "Epoch 1: 1.8394063711166382\n",
      "Epoch 1: 2.290877342224121\n",
      "Epoch 1: 1.9083786010742188\n",
      "Epoch 1: 2.392232894897461\n",
      "Epoch 1: 2.3036105632781982\n",
      "Epoch 1: 2.0614757537841797\n",
      "Epoch 1: 2.0260190963745117\n",
      "Epoch 1: 1.829660177230835\n",
      "Epoch 1: 1.9020270109176636\n",
      "Epoch 1: 1.8883708715438843\n",
      "Epoch 1: 2.0022521018981934\n",
      "Epoch 1: 2.079589605331421\n",
      "Epoch 1: 1.879281759262085\n",
      "Epoch 1: 2.0405776500701904\n",
      "Epoch 1: 1.847642421722412\n",
      "Epoch 1: 2.2273309230804443\n",
      "Epoch 1: 1.5739619731903076\n",
      "Epoch 1: 2.2724556922912598\n",
      "Epoch 1: 1.8528926372528076\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 64\u001b[0m\n\u001b[1;32m     59\u001b[0m             optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     60\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m train_model(lookback_horizon\u001b[39m=\u001b[39;49m \u001b[39m96\u001b[39;49m,\n\u001b[1;32m     65\u001b[0m forecast_size\u001b[39m=\u001b[39;49m \u001b[39m24\u001b[39;49m,\n\u001b[1;32m     66\u001b[0m batch_size\u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m,\n\u001b[1;32m     67\u001b[0m num_nhits_blocks\u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,\n\u001b[1;32m     68\u001b[0m mlp_layer_num\u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m     69\u001b[0m hidden_size\u001b[39m=\u001b[39;49m \u001b[39m512\u001b[39;49m,\n\u001b[1;32m     70\u001b[0m pooling_kernel_size\u001b[39m=\u001b[39;49m [\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m],\n\u001b[1;32m     71\u001b[0m dropout_prob\u001b[39m=\u001b[39;49m \u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     72\u001b[0m downsampling_ratios\u001b[39m=\u001b[39;49m [\u001b[39m4\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(lookback_horizon, forecast_size, batch_size, num_nhits_blocks, mlp_layer_num, hidden_size, pooling_kernel_size, downsampling_ratios, dropout_prob)\u001b[0m\n\u001b[1;32m     45\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     51\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[0;32m~/code/nhits/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/nhits/src/nhits.py:84\u001b[0m, in \u001b[0;36mNHiTS.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m bc_coefs, fc_coefs \u001b[39m=\u001b[39m block(res_stream)\n\u001b[1;32m     83\u001b[0m bc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbc_predictors(bc_coefs)\n\u001b[0;32m---> 84\u001b[0m fc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_predictors(fc_coefs)\n\u001b[1;32m     85\u001b[0m forecasts\u001b[39m.\u001b[39mappend(fc)\n\u001b[1;32m     86\u001b[0m res_stream \u001b[39m=\u001b[39m res_stream \u001b[39m-\u001b[39m bc\n",
      "File \u001b[0;32m~/code/nhits/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/nhits/src/interpolater.py:24\u001b[0m, in \u001b[0;36mInterpolater.forward\u001b[0;34m(self, knots)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, knots):\n\u001b[0;32m---> 24\u001b[0m     forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpolate(knots)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m forecast\n",
      "File \u001b[0;32m~/code/nhits/src/interpolater.py:21\u001b[0m, in \u001b[0;36mInterpolater._interpolate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_interpolate\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     20\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49minterpolate(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecast_size, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation_mode)\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/code/nhits/venv/lib/python3.11/site-packages/torch/nn/functional.py:3954\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3952\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   3953\u001b[0m     \u001b[39massert\u001b[39;00m align_corners \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 3954\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mupsample_linear1d(\u001b[39minput\u001b[39;49m, output_size, align_corners, scale_factors)\n\u001b[1;32m   3955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   3956\u001b[0m     \u001b[39massert\u001b[39;00m align_corners \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = UnivariateTSDataset(\n",
    "    path='../data/ETTm2.csv', \n",
    "    col='MULL', # replace 'desired_column' with the column name you want\n",
    "    lookback_horizon=96, \n",
    "    forecast_horizon=24\n",
    ")\n",
    "\n",
    "# Initialize a DataLoader with your dataset\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "losses = []\n",
    "\n",
    "def train_model(lookback_horizon, forecast_size, batch_size, num_nhits_blocks, mlp_layer_num, hidden_size, pooling_kernel_size, downsampling_ratios, dropout_prob):\n",
    "    model = NHiTS(\n",
    "        lookback_horizon=lookback_horizon,\n",
    "        forecast_size=forecast_size,\n",
    "        num_nhits_blocks=num_nhits_blocks,\n",
    "        mlp_layer_num=mlp_layer_num,\n",
    "        hidden_size=hidden_size,\n",
    "        pooling_kernel_size=pooling_kernel_size,\n",
    "        downsampling_ratios=downsampling_ratios,\n",
    "        dropout_prob=dropout_prob\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    # Create a list to store loss values of the last 10 epochs\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "        for batch in dataloader:  # assuming dataloader is previously defined\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prepare the inputs and targets\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            losses.append(loss)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            print(f'Epoch {epoch}: {loss}')\n",
    "\n",
    "\n",
    "\n",
    "train_model(lookback_horizon= 96,\n",
    "forecast_size= 24,\n",
    "batch_size= 128,\n",
    "num_nhits_blocks= 3,\n",
    "mlp_layer_num= 2,\n",
    "hidden_size= 512,\n",
    "pooling_kernel_size= [2, 2, 1],\n",
    "dropout_prob= 0.0,\n",
    "downsampling_ratios= [4, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ab1040d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.9858)\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(torch.tensor(losses[-256:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nhits import NHiTSMulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data.shape=(69680, 3)\n"
     ]
    }
   ],
   "source": [
    "#...\n",
    "from dataset.dataset import MultivariateTSDataset\n",
    "# Initialize your dataset\n",
    "dataset = MultivariateTSDataset(\n",
    "    path='../data/ETTm2.csv', \n",
    "    cols=['MULL', 'OT', 'LULL'],  # list of desired columns\n",
    "    lookback_horizon=120, \n",
    "    forecast_horizon=24\n",
    ")\n",
    "\n",
    "# Initialize a DataLoader with your dataset\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def train_model(lookback_horizon, forecast_size, batch_size, num_nhits_blocks, mlp_layer_num, hidden_size, pooling_kernel_size, downsampling_ratios, dropout_prob):\n",
    "    model = NHiTSMulti(\n",
    "        lookback_horizon=lookback_horizon,\n",
    "        forecast_size=forecast_size,\n",
    "        num_nhits_blocks=num_nhits_blocks,\n",
    "        mlp_layer_num=mlp_layer_num,\n",
    "        hidden_size=hidden_size,\n",
    "        pooling_kernel_size=pooling_kernel_size,\n",
    "        downsampling_ratios=downsampling_ratios,\n",
    "        dropout_prob=dropout_prob\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    # Create a list to store loss values of the last 10 epochs\n",
    "    last_ten_losses = []\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "        for batch in dataloader:  # assuming dataloader is previously defined\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prepare the inputs and targets\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, targets)\n",
    "            losses.append(loss)\n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            print(f'Epoch {epoch}: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'bool' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(\u001b[39m120\u001b[39;49m,\u001b[39m24\u001b[39;49m,\u001b[39m256\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m512\u001b[39;49m,[\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m2\u001b[39;49m],[\u001b[39m4\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m1\u001b[39;49m],\u001b[39m0.0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[10], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(lookback_horizon, forecast_size, batch_size, num_nhits_blocks, mlp_layer_num, hidden_size, pooling_kernel_size, downsampling_ratios, dropout_prob)\u001b[0m\n\u001b[1;32m     43\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     49\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[0;32m~/code/nhits/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/nhits/src/nhits.py:142\u001b[0m, in \u001b[0;36mNHiTSMulti.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m forecasts \u001b[39m=\u001b[39m []\n\u001b[1;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m--> 142\u001b[0m     bc_coefs, fc_coefs \u001b[39m=\u001b[39m block(res_stream)\n\u001b[1;32m    143\u001b[0m     bc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbc_predictors(bc_coefs)\n\u001b[1;32m    144\u001b[0m     fc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_predictors(fc_coefs)\n",
      "File \u001b[0;32m~/code/nhits/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/nhits/src/nhits_block.py:123\u001b[0m, in \u001b[0;36mNHiTSMulti_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(x\u001b[39m.\u001b[39;49mshape\u001b[39m==\u001b[39;49m\u001b[39m3\u001b[39;49m):\n\u001b[1;32m    124\u001b[0m         x\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mview((x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[1;32m    125\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooling_kernel(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'bool' has no len()"
     ]
    }
   ],
   "source": [
    "train_model(120,24,256,3,3,512,[2,2,2],[4,2,1],0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
